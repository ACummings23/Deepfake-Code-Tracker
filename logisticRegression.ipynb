{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import librosa.display\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset initialization\n",
    "dfInput=pd.read_csv('/code/dataset/FakeAVCeleb/MergedMetadataLabeled.csv')\n",
    "dfCut=dfInput[['wavLocation','Audio_Label','source']]\n",
    "dfFake=dfCut[dfCut['Audio_Label']==1].reset_index(drop=True)\n",
    "dfReal=dfCut[dfCut['Audio_Label']==0].reset_index(drop=True)\n",
    "dfTraining=pd.concat([dfReal[0:8000],dfFake[0:8000]]).reset_index(drop=True)\n",
    "dfValidation=pd.concat([dfReal[8000:],dfFake[8000:]]).reset_index(drop=True)\n",
    "labelsTrain=dfTraining['Audio_Label']\n",
    "labelsVal=dfValidation['Audio_Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##generate MFCCs for Real and Fake Audiofiles\n",
    "r_mfccs=[]\n",
    "r_spec_data=[]\n",
    "r_sampling_rate=[]\n",
    "for i in range(0,len(r_spec_data)):\n",
    "    data,sampling_rate=librosa.load(dfReal['wavLocation'][i])\n",
    "    r_spec_data+=[data]\n",
    "    r_sampling_rate+=[sampling_rate]\n",
    "    mfccs = librosa.feature.mfcc(data, sr=sampling_rate, n_mfcc=20,dtype=np.float64)\n",
    "    r_mfccs.append(mfccs)\n",
    "\n",
    "f_mfccs=[] \n",
    "f_spec_data=[]\n",
    "f_sampling_rate=[]\n",
    "for i in range(0,len(f_spec_data)):\n",
    "    data,sampling_rate=librosa.load(dfFake['wavLocation'][i])\n",
    "    f_spec_data=[data]\n",
    "    f_sampling_rate+=[sampling_rate]\n",
    "    mfccs = librosa.feature.mfcc(data, sr=sampling_rate, n_mfcc=20,dtype=np.float64)\n",
    "    f_mfccs.append(mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wavLocation</th>\n",
       "      <th>Audio_Label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>/code/dataset/FakeAVCeleb/RealVideo-FakeAudio/...</td>\n",
       "      <td>1</td>\n",
       "      <td>id00076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>/code/dataset/FakeAVCeleb/RealVideo-FakeAudio/...</td>\n",
       "      <td>1</td>\n",
       "      <td>id00166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>/code/dataset/FakeAVCeleb/RealVideo-FakeAudio/...</td>\n",
       "      <td>1</td>\n",
       "      <td>id00173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>/code/dataset/FakeAVCeleb/RealVideo-FakeAudio/...</td>\n",
       "      <td>1</td>\n",
       "      <td>id00366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>/code/dataset/FakeAVCeleb/RealVideo-FakeAudio/...</td>\n",
       "      <td>1</td>\n",
       "      <td>id00391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21561</th>\n",
       "      <td>/code/dataset/FakeAVCeleb/FakeVideo-FakeAudio/...</td>\n",
       "      <td>1</td>\n",
       "      <td>id09181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21562</th>\n",
       "      <td>/code/dataset/FakeAVCeleb/FakeVideo-FakeAudio/...</td>\n",
       "      <td>1</td>\n",
       "      <td>id09181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21563</th>\n",
       "      <td>/code/dataset/FakeAVCeleb/FakeVideo-FakeAudio/...</td>\n",
       "      <td>1</td>\n",
       "      <td>id09181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21564</th>\n",
       "      <td>/code/dataset/FakeAVCeleb/FakeVideo-FakeAudio/...</td>\n",
       "      <td>1</td>\n",
       "      <td>id09181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21565</th>\n",
       "      <td>/code/dataset/FakeAVCeleb/FakeVideo-FakeAudio/...</td>\n",
       "      <td>1</td>\n",
       "      <td>id09181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11357 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             wavLocation  Audio_Label   source\n",
       "500    /code/dataset/FakeAVCeleb/RealVideo-FakeAudio/...            1  id00076\n",
       "501    /code/dataset/FakeAVCeleb/RealVideo-FakeAudio/...            1  id00166\n",
       "502    /code/dataset/FakeAVCeleb/RealVideo-FakeAudio/...            1  id00173\n",
       "503    /code/dataset/FakeAVCeleb/RealVideo-FakeAudio/...            1  id00366\n",
       "504    /code/dataset/FakeAVCeleb/RealVideo-FakeAudio/...            1  id00391\n",
       "...                                                  ...          ...      ...\n",
       "21561  /code/dataset/FakeAVCeleb/FakeVideo-FakeAudio/...            1  id09181\n",
       "21562  /code/dataset/FakeAVCeleb/FakeVideo-FakeAudio/...            1  id09181\n",
       "21563  /code/dataset/FakeAVCeleb/FakeVideo-FakeAudio/...            1  id09181\n",
       "21564  /code/dataset/FakeAVCeleb/FakeVideo-FakeAudio/...            1  id09181\n",
       "21565  /code/dataset/FakeAVCeleb/FakeVideo-FakeAudio/...            1  id09181\n",
       "\n",
       "[11357 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCut[dfCut['Audio_Label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import audioread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10209"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfCut[dfCut['Audio_Label']==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCut_Sample=dfCut.sample(n=500, replace=True,random_state=42).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dfCut_Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list=dfCut_Sample['wavLocation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/code/dataset/FakeAVCeleb/FakeVideo-FakeAudio/Caucasian (European)/men/id01154/00118_id01052_wavtolip.mp4.wav'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(sr=16000):\n",
    "    temp_list = dfCut_Sample['wavLocation']\n",
    "    r_audio = []\n",
    "    f_audio = []\n",
    "    for i in range(0,len(dfCut_Sample)):\n",
    "        if dfCut_Sample['Audio_Label'][i]==0:\n",
    "            r_audio.append(librosa.load(temp_list[i],sr=sr/2))\n",
    "            #with audioread.audio_open(temp_list[i]) as input_file:\n",
    "                #channel_r.append(input_file.channels)\n",
    "        else:\n",
    "            f_audio.append(librosa.load(temp_list[i],sr=sr/2))\n",
    "            #with audioread.audio_open(temp_list[i]) as input_file:\n",
    "                #channel_f.append(input_file.channels)\n",
    "        \n",
    "            \n",
    "    print('Real audio files loaded: ' + str(len(r_audio)) + ' samples')\n",
    "    print('Fake audio files loaded: ' + str(len(f_audio)) + ' samples')\n",
    "    return r_audio,f_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real audio files loaded: 239 samples\n",
      "Fake audio files loaded: 261 samples\n"
     ]
    }
   ],
   "source": [
    "#Loading of the Data / Counting of Channels \n",
    "r_audio,f_audio = load_data()\n",
    "n_r = len(r_audio)\n",
    "n_f = len(f_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161600"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mel_frequencies(r_audio,f_audio,sr=16000):\n",
    "    r_mel_frequencies = []\n",
    "    f_mel_frequencies = []\n",
    "    \n",
    "    for i in range(len(r_audio)):\n",
    "        r_mel_frequencies.append(librosa.feature.melspectrogram(y=np.array(r_audio[i][0]),sr=sr/2))\n",
    "    for i in range(len(f_audio)):\n",
    "        f_mel_frequencies.append(librosa.feature.melspectrogram(y=np.array(f_audio[i][0]),sr=sr/2))\n",
    "        \n",
    "    return r_mel_frequencies,f_mel_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mfccs(r_mel_frequencies,f_mel_frequencies,sr=16000):\n",
    "    r_mfccs = []\n",
    "    f_mfccs = []\n",
    "    \n",
    "    for i in range(len(r_mel_frequencies)):\n",
    "        r_mfccs.append(librosa.feature.mfcc(S=librosa.power_to_db(r_mel_frequencies[i]),sr=sr/2))\n",
    "    for i in range(len(f_mel_frequencies)):\n",
    "        f_mfccs.append(librosa.feature.mfcc(S=librosa.power_to_db(f_mel_frequencies[i]),sr=sr/2))\n",
    "        \n",
    "    return r_mfccs,f_mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_df_mfccs(r_mfccs,f_mfccs):\n",
    "    df_r = pd.DataFrame(np.transpose(r_mfccs[0]),index=np.ones(len(np.transpose(r_mfccs[0])))*(0+1))\n",
    "    for i in range(1,len(r_mfccs)):\n",
    "        df_temp = pd.DataFrame(np.transpose(r_mfccs[i]),index=np.ones(len(np.transpose(r_mfccs[i])))*(i+1))\n",
    "        frames = [df_r, df_temp]\n",
    "        df_r = pd.concat(frames)\n",
    "    df_r['Label']=0\n",
    "    \n",
    "    df_f = pd.DataFrame(np.transpose(f_mfccs[0]),index=np.ones(len(np.transpose(f_mfccs[0])))*(0+len(r_mfccs)+1))\n",
    "    for i in range(1,len(f_mfccs)):\n",
    "        df_temp = pd.DataFrame(np.transpose(f_mfccs[i]),index=np.ones(len(np.transpose(f_mfccs[i])))*(i+len(r_mfccs)+1))\n",
    "        frames = [df_f, df_temp]\n",
    "        df_f = pd.concat(frames)\n",
    "    df_f['Label']=1\n",
    "    \n",
    "    frames = [df_r, df_f]\n",
    "    result = pd.concat(frames)\n",
    "    \n",
    "    result = result.sample(frac=1)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def remove_frames(r_audio,f_audio,r_frames,f_frames,sr=16000):\n",
    "    \n",
    "    detect_r = []\n",
    "    detect_f = []\n",
    "    \n",
    "    for r in r_audio:\n",
    "        detect_r.append(librosa.onset.onset_detect(y=r[0]))\n",
    "    for f in f_audio:\n",
    "        detect_f.append(librosa.onset.onset_detect(y=f[0]))\n",
    "    \n",
    "    \n",
    "    new_r_frames = []\n",
    "    new_f_frames = []\n",
    "    \n",
    "    for k in range(len(r_frames)):\n",
    "        new_r_frames.append([[r_frames[k][i][j] for j in detect_r[k]] for i in range(len(r_frames[0]))])   \n",
    "    for k in range(len(f_frames)):\n",
    "        new_f_frames.append([[f_frames[k][i][j] for j in detect_f[k]] for i in range(len(f_frames[0]))])\n",
    "        \n",
    "    return new_r_frames,new_f_frames\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r_frames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [92], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m r_frames\u001b[39m.\u001b[39msize\n",
      "\u001b[0;31mNameError\u001b[0m: name 'r_frames' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(r_frames,f_frames,n_r,n_f,test_size=0.3):\n",
    "    y_r = np.zeros(n_r)\n",
    "    y_f = np.ones(n_f)\n",
    "\n",
    "    X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(r_frames, y_r, test_size= test_size,random_state=42)\n",
    "    X_train_f, X_test_f, y_train_f, y_test_f = train_test_split(f_frames, y_f, test_size= test_size,random_state=42)\n",
    "\n",
    "    df_train = build_df_mfccs(X_train_r,X_train_f)\n",
    "    df_test = build_df_mfccs(X_test_r,X_test_f)\n",
    "    \n",
    "    return df_train,df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_r=np.zeros(n_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2342"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def log_reg(df_train,df_test):\n",
    "    logreg = LogisticRegression()\n",
    "    X_train=df_train.iloc[:,0:df_train.shape[1]-1]\n",
    "    X_test = df_test.iloc[:,0:df_train.shape[1]-1]\n",
    "    y_train=df_train['Label']\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred_train = logreg.predict(X_train)\n",
    "    y_pred_test = logreg.predict(X_test)\n",
    "\n",
    "    pred_train_series = pd.Series(y_pred_train,index = df_train.index)\n",
    "    pred_group_train_series = pred_train_series.groupby(pred_train_series.index).mean()\n",
    "    pred_train_boolean = pred_group_train_series >=0.5\n",
    "    y_pred_train_last= pred_train_boolean*1\n",
    "\n",
    "    pred_test_series = pd.Series(y_pred_test,index = df_test.index)\n",
    "    pred_group_test_series = pred_test_series.groupby(pred_test_series.index).mean()\n",
    "    pred_test_boolean = pred_group_test_series >=0.5\n",
    "    y_pred_test_last= pred_test_boolean*1\n",
    "\n",
    "    y_train = df_train['Label']\n",
    "    y_train_last = y_train.groupby(y_train.index).mean()\n",
    "\n",
    "    y_test = df_test['Label']\n",
    "    y_test_last = y_test.groupby(y_test.index).mean()\n",
    "    \n",
    "    return y_train_last,y_pred_train_last,y_test_last,y_pred_test_last\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracies(y_train,y_pred_train,y_test,y_pred_test):\n",
    "    train_accuracy = np.sum(np.array([y_train==y_pred_train]))/len(y_train)\n",
    "    test_accuracy = np.sum(np.array([y_test==y_pred_test]))/len(y_test)\n",
    "    return train_accuracy, test_accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_report(y_train,y_pred_train,y_test,y_pred_test,train_accuracy,test_accuracy):\n",
    "    \n",
    "    print('\\n\\nTraining Set:\\n')\n",
    "    print('Training Confusion Matrix:')\n",
    "    print(confusion_matrix(y_train, y_pred_train))\n",
    "    \n",
    "    print('Training Classification report:')\n",
    "    print(classification_report(y_train, y_pred_train))\n",
    "    \n",
    "    print('Train Accuracy: ' + str(train_accuracy))\n",
    "    \n",
    "    print('\\n\\nTest Set:\\n')\n",
    "    print('Test Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred_test))\n",
    "    \n",
    "    print('Test Classification report:')\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "    print('Test Accuracy: ' + str(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(df_train,folds):\n",
    "    \n",
    "    C_range = np.logspace(-2, 10, 13)\n",
    "    gamma_range = np.logspace(-9, 3, 13)\n",
    "    results=np.empty((folds,len(C_range),len(gamma_range)))\n",
    "    i=0\n",
    "    j=0\n",
    "    k=0\n",
    "    X = np.unique(df_train.index.values)\n",
    "    np.random.shuffle(X)\n",
    "    kf = KFold(n_splits=3)\n",
    "    kf.get_n_splits(X)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = df_train.loc[X[train_index]], df_train.loc[X[test_index]]\n",
    "\n",
    "        for C in C_range:\n",
    "            for gamma in gamma_range:\n",
    "                y_train_last_svm,y_pred_train_last_svm,y_test_last_svm,y_pred_test_last_svm = classification_svm(X_train,X_test,C,gamma)\n",
    "                train_acc,test_acc = calculate_accuracies(y_train=y_train_last_svm, y_pred_train = y_pred_train_last_svm, y_test = y_test_last_svm,y_pred_test = y_pred_test_last_svm)\n",
    "                results[k,i,j]=test_acc\n",
    "                j+=1\n",
    "            i+=1\n",
    "            j=0\n",
    "        k+=1\n",
    "        i=0\n",
    "    average_acc = np.sum(results,axis=0)/folds\n",
    "    indexes_max = np.unravel_index(np.argmax(average_acc, axis=None), average_acc.shape)\n",
    "    best_C = C_range[indexes_max[0]]    \n",
    "    best_gamma = gamma_range[indexes_max[1]] \n",
    "        \n",
    "    return best_C, best_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'svm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msvm\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'svm'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_svm(df_train,df_test,C,gamma):\n",
    "    clf = svm.SVC(C=C, gamma = gamma)\n",
    "    X_train=df_train.iloc[:,0:df_train.shape[1]-1]\n",
    "    X_test = df_test.iloc[:,0:df_train.shape[1]-1]\n",
    "    y_train=df_train['Label']\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "\n",
    "    pred_train_series = pd.Series(y_pred_train,index = df_train.index)\n",
    "    pred_group_train_series = pred_train_series.groupby(pred_train_series.index).mean()\n",
    "    pred_train_boolean = pred_group_train_series >=0.5\n",
    "    y_pred_train_last= pred_train_boolean*1\n",
    "\n",
    "    pred_test_series = pd.Series(y_pred_test,index = df_test.index)\n",
    "    pred_group_test_series = pred_test_series.groupby(pred_test_series.index).mean()\n",
    "    pred_test_boolean = pred_group_test_series >=0.5\n",
    "    y_pred_test_last= pred_test_boolean*1\n",
    "\n",
    "    y_train = df_train['Label']\n",
    "    y_train_last = y_train.groupby(y_train.index).mean()\n",
    "\n",
    "    y_test = df_test['Label']\n",
    "    y_test_last = y_test.groupby(y_test.index).mean()\n",
    "    \n",
    "    return y_train_last,y_pred_train_last,y_test_last,y_pred_test_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing of the Mel-scaled spectrograms for each audio file\n",
    "r_mel_frequencies, f_mel_frequencies = compute_mel_frequencies(r_audio,f_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing of the Mel-frequency cepstral coefficients for each audio file\n",
    "r_mfccs, f_mfccs = compute_mfccs(r_mel_frequencies,f_mel_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2658"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f_mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing silent frames for delta features and mfccs for each audio file\n",
    "new_r_mfccs,new_f_mfccs = remove_frames(r_audio,f_audio,r_mfccs,f_mfccs)\n",
    "#new_r_deltas, new_f_deltas = remove_frames(cats,dogs,cats_deltas, dogs_deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [99], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mlen\u001b[39m(new_f_mfccs[\u001b[39m0\u001b[39;49m])\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "len(new_f_mfccs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_test = split_data(new_r_mfccs,new_f_mfccs,n_r=n_r,n_f=n_f,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#Plot onset detection results of audio file cats_1\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m detect \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39monset\u001b[39m.\u001b[39monset_detect(y\u001b[39m=\u001b[39mx)\n\u001b[1;32m      3\u001b[0m onset_times \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39mframes_to_time(detect)\n\u001b[1;32m      4\u001b[0m plt\u001b[39m.\u001b[39mplot(onset_times, np\u001b[39m.\u001b[39mzeros_like(onset_times) \u001b[39m+\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "#Plot onset detection results of audio file cats_1\n",
    "detect = librosa.onset.onset_detect(y=x)\n",
    "onset_times = librosa.frames_to_time(detect)\n",
    "plt.plot(onset_times, np.zeros_like(onset_times) + 0, 'x')\n",
    "plt.show()\n",
    "print(\"Non silent frame indexes: \" + str(detect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 2342]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [87], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_train,df_test \u001b[39m=\u001b[39m split_data(new_r_mfccs,new_f_mfccs,n_r\u001b[39m=\u001b[39;49mn_r,n_f\u001b[39m=\u001b[39;49mn_f,test_size\u001b[39m=\u001b[39;49m\u001b[39m0.3\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn [12], line 5\u001b[0m, in \u001b[0;36msplit_data\u001b[0;34m(r_frames, f_frames, n_r, n_f, test_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m y_r \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(n_r)\n\u001b[1;32m      3\u001b[0m y_f \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones(n_f)\n\u001b[0;32m----> 5\u001b[0m X_train_r, X_test_r, y_train_cats, y_test_cats \u001b[39m=\u001b[39m train_test_split(r_frames, y_r, test_size\u001b[39m=\u001b[39;49m test_size, random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m)\n\u001b[1;32m      6\u001b[0m X_train_f, X_test_f, y_train_dogs, y_test_dogs \u001b[39m=\u001b[39m train_test_split(f_frames, y_f, test_size\u001b[39m=\u001b[39m test_size, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m      8\u001b[0m df_train \u001b[39m=\u001b[39m build_df_mfccs(X_train_r,X_train_f)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_split.py:2445\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2442\u001b[0m \u001b[39mif\u001b[39;00m n_arrays \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   2443\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAt least one array required as input\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2445\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39;49marrays)\n\u001b[1;32m   2447\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[1;32m   2448\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2449\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m\n\u001b[1;32m   2450\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:433\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[39m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \n\u001b[1;32m    416\u001b[0m \u001b[39mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[39m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    432\u001b[0m result \u001b[39m=\u001b[39m [_make_indexable(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m iterables]\n\u001b[0;32m--> 433\u001b[0m check_consistent_length(\u001b[39m*\u001b[39;49mresult)\n\u001b[1;32m    434\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    385\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    386\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 387\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    390\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 2342]"
     ]
    }
   ],
   "source": [
    "df_train,df_test = split_data(new_r_mfccs,new_f_mfccs,n_r=n_r,n_f=n_f,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Set:\n",
      "\n",
      "Training Confusion Matrix:\n",
      "[[137  30]\n",
      " [ 53 129]]\n",
      "Training Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.82      0.77       167\n",
      "         1.0       0.81      0.71      0.76       182\n",
      "\n",
      "    accuracy                           0.76       349\n",
      "   macro avg       0.77      0.76      0.76       349\n",
      "weighted avg       0.77      0.76      0.76       349\n",
      "\n",
      "Train Accuracy: 0.7621776504297995\n",
      "\n",
      "\n",
      "Test Set:\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[56 16]\n",
      " [34 45]]\n",
      "Test Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.78      0.69        72\n",
      "         1.0       0.74      0.57      0.64        79\n",
      "\n",
      "    accuracy                           0.67       151\n",
      "   macro avg       0.68      0.67      0.67       151\n",
      "weighted avg       0.68      0.67      0.67       151\n",
      "\n",
      "Test Accuracy: 0.6688741721854304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "y_train_last_lr,y_pred_train_last_lr,y_test_last_lr,y_pred_test_last_lr = log_reg(df_train,df_test)\n",
    "train_acc_lr,test_acc_lr = calculate_accuracies(y_train=y_train_last_lr, y_pred_train = y_pred_train_last_lr, y_test = y_test_last_lr,y_pred_test = y_pred_test_last_lr)\n",
    "class_report(y_train_last_lr,y_pred_train_last_lr,y_test_last_lr,y_pred_test_last_lr,train_acc_lr,test_acc_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "C,gamma = cross_validate(df_train,folds=1)\n",
    "y_train_last_svm,y_pred_train_last_svm,y_test_last_svm,y_pred_test_last_svm = classification_svm(df_train,df_test,C,gamma)\n",
    "train_acc_svm,test_acc_svm = calculate_accuracies(y_train=y_train_last_svm, y_pred_train = y_pred_train_last_svm, y_test = y_test_last_svm,y_pred_test = y_pred_test_last_svm)\n",
    "class_report(y_train_last_svm,y_pred_train_last_svm,y_test_last_svm,y_pred_test_last_svm,train_acc_svm,test_acc_svm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2 (default, Feb 28 2021, 17:03:44) \n[GCC 10.2.1 20210110]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
